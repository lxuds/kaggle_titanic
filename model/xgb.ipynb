{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scikit_learn-0.18.1-py2.7-linux-x86_64.egg/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/scikit_learn-0.18.1-py2.7-linux-x86_64.egg/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import xgboost as xgb\n",
    "sns.set_style('whitegrid') \n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn import pipeline, grid_search\n",
    "\n",
    "import random\n",
    "random.seed(2016)\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Features Set: 0.0 minutes ---\n",
      "6000\n",
      "<xgboost.core.Booster object at 0x7f6c77f873d0>\n",
      "5999\n",
      "\n",
      "\n",
      "Model Report\n"
     ]
    }
   ],
   "source": [
    "def main(input1='../data/preprocessing_train_df.csv', input2='../data/preprocessing_test_df.csv'):\n",
    "\n",
    "    \n",
    "    \n",
    "    start_time = time.time() \n",
    "    \n",
    "#load preprocessed training data as a dataframe\n",
    "    train_df = pd.read_csv(input1, index_col=0)\n",
    "    test_df  = pd.read_csv(input2, index_col=0)\n",
    "\n",
    "#  test_df = pd.read_csv(\"../data/preprocessing_test_df.csv\" , index_col=0)\n",
    "\n",
    "    x_train = train_df.iloc[:, 2:].as_matrix()\n",
    "    y_train = train_df.iloc[:, 1]\n",
    "\n",
    "    id_test = test_df['PassengerId']\n",
    "    x_test = test_df.iloc[:,1:].as_matrix()\n",
    "#    x_train.info()\n",
    "    \n",
    "    \n",
    "    print('--- Features Set: %s minutes ---' % round(((time.time() - start_time) / 60), 2))\n",
    "#    print('Number of Features: ', len(x_train.columns.tolist()))\n",
    "    \n",
    "\n",
    "# Step 1: Fix learning rate and # of estimators for tuning tree-based parameters #\n",
    "#    clf= xgb.XGBClassifier(\n",
    "    params ={\n",
    "#        n_estimators=500,\n",
    "        'booster':'gbtree',\n",
    "        'objective':'binary:logistic', \n",
    "        'eta':0.5,\n",
    "        'max_depth':3,\n",
    "        'min_child_weight':1,\n",
    "        'gamma':0,\n",
    "        'subsample':0.8,\n",
    "        'colsample_bytree':0.8, \n",
    "        'seed':2016, \n",
    "        'nthread':4, \n",
    "        'eval_metrics':'auc',\n",
    "        'scale_pos_weight':1\n",
    "    }\n",
    "    xgtrain = xgb.DMatrix(x_train, label=y_train)    \n",
    "\n",
    "    num_round = 500    \n",
    "    xgb1_result = xgb.train(params, xgtrain, num_boost_round=6000, )\n",
    "    print xgb1_result.best_ntree_limit\n",
    "    print xgb1_result\n",
    "    print xgb1_result.best_iteration\n",
    "#    print xgb1_result.best_score\n",
    "    #  evals_result = clf.evals_result()\n",
    "    #print evals_result\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#    xgb_param = clf.get_xgb_params()\n",
    "#    xgtrain = xgb.DMatrix(x_train, y_train)    \n",
    "#    cv_result= xgb.cv(xgb_param, xgtrain, num_boost_round=clf.get_params()['n_estimators'],\n",
    "#                      nfold=5, early_stopping_rounds=50, metrics='auc')\n",
    "    \n",
    "#    clf.set_params(n_estimators=cv_result.shape[0])\n",
    "    \n",
    "#    print cv_result\n",
    "   # y_train_predictions = clf.predict(x_train)\n",
    "   # y_train_predprob = clf.predict_proba(x_train)[:,1]\n",
    "    \n",
    "    print \n",
    "#    xgb.plot_importance(xgb1_result)\n",
    "#    xgb.plot_tree(xgb1_result)\n",
    "\n",
    "    \n",
    "     #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    #print \"Accuracy : %.4g\" % metrics.accuracy_score(y_train, dtrain_predictions)\n",
    " #   print \"AUC Score (Train): %f\" % eval_metrics(y_train, y_train_predprob)\n",
    "                    \n",
    "#    feat_imp = pd.Series(clf.booster().get_fscore()).sort_values(ascending=False)\n",
    "#    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#    plt.ylabel('Feature Importance Score')\n",
    "\n",
    "\n",
    "## Grid Search for XGBClassifier    \n",
    "#    clf = xgb.XGBClassifier(seed=2016)\n",
    "\n",
    "#    param_grid = {\n",
    "#        'n_estimators': [300,500],\n",
    "#        'learning_rate': [0.045, 0.05, 0.055],\n",
    "#        'max_depth': [4,5,6,7],\n",
    "#        'subsample': [0.7, 0.75, 0.8],\n",
    "#        'colsample_bytree': [0.4, 0.6, 0.8] \n",
    "#    }\n",
    "        \n",
    "    \n",
    "\n",
    "#    model = grid_search.GridSearchCV(estimator=clf, param_grid=param_grid, \n",
    "#                                     scoring='accuracy', cv=5, n_jobs=1)\n",
    "#    model.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "#    print('--- Grid Search Completed: %s minutes ---' % round(((time.time() - start_time) / 60), 2))\n",
    "#    print('Param grid:')\n",
    "#    print(param_grid)\n",
    "#    print('Best Params:')\n",
    "#    print(model.best_params_)\n",
    "#    print('Best CV Score:')\n",
    "#    print(-model.best_score_)\n",
    "\n",
    "    \n",
    "#    y_pred = model.predict(x_test)\n",
    "\n",
    "#    pd.DataFrame({'PassengerId': id_test, 'Survived': y_pred}).to_csv('../data/submission_xgb.csv', index=False)\n",
    "    \n",
    "#    print('--- Submission Generated: %s minutes ---' % round(((time.time() - start_time) / 60), 2))\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
